#!/usr/bin/env python3
"""
AI GitHub Daily Tracker - AIé¡¹ç›®æ¯æ—¥è¿½è¸ªå™¨
æ¯å¤©è‡ªåŠ¨å‘ç°å¹¶æ¨é€æœ€å€¼å¾—å…³æ³¨çš„AIå¼€æºé¡¹ç›®
"""

import os
import json
import time
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import requests
from dateutil import parser as date_parser

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼ˆç”¨äºæœ¬åœ°æµ‹è¯•ï¼‰
try:
    from load_env import load_env
    load_env()
except ImportError:
    pass


class GitHubAPIClient:
    """GitHub APIå®¢æˆ·ç«¯ï¼Œè´Ÿè´£è·å–é¡¹ç›®æ•°æ®"""

    def __init__(self, token: Optional[str] = None):
        self.token = token or os.getenv('GH_TOKEN')
        self.base_url = 'https://api.github.com'
        self.session = requests.Session()
        if self.token:
            self.session.headers.update({'Authorization': f'token {self.token}'})

        self.logger = logging.getLogger(__name__)

    def search_repositories(self, query: str, sort: str = 'stars', order: str = 'desc', per_page: int = 50) -> List[Dict]:
        """æœç´¢GitHubä»“åº“"""
        url = f'{self.base_url}/search/repositories'
        params = {
            'q': query,
            'sort': sort,
            'order': order,
            'per_page': per_page
        }

        try:
            response = self.session.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            self.logger.info(f"GitHub APIè¯·æ±‚æˆåŠŸï¼Œæ‰¾åˆ° {data.get('total_count', 0)} ä¸ªé¡¹ç›®")
            return data.get('items', [])
        except requests.exceptions.RequestException as e:
            self.logger.error(f"GitHub APIè¯·æ±‚å¤±è´¥: {e}")
            return []

    def get_popular_ai_projects(self) -> List[Dict]:
        """è·å–æœ€å—æ¬¢è¿çš„AIé¡¹ç›®ï¼ˆæŒ‰staræ•°æ’åºï¼‰"""
        # åˆ†å¤šæ¬¡æŸ¥è¯¢ä¸åŒçš„AIé¢†åŸŸï¼Œé¿å…æŸ¥è¯¢è¿‡é•¿
        queries = [
            'machine learning OR "artificial intelligence" OR "deep learning"',
            'tensorflow OR pytorch OR keras',
            'nlp OR "natural language processing" OR transformer OR gpt',
            '"computer vision" OR opencv OR yolo'
        ]

        all_projects = []
        for query in queries:
            projects = self.search_repositories(query, sort='stars', per_page=25)
            all_projects.extend(projects)
            time.sleep(1)  # é¿å…APIé™åˆ¶

        # å»é™¤é‡å¤é¡¹ç›®ï¼ˆåŸºäºIDï¼‰
        seen_ids = set()
        unique_projects = []
        for project in all_projects:
            if project['id'] not in seen_ids:
                seen_ids.add(project['id'])
                unique_projects.append(project)

        return unique_projects

    def get_trending_ai_projects(self) -> List[Dict]:
        """è·å–è¶‹åŠ¿AIé¡¹ç›®ï¼ˆæŒ‰æ›´æ–°æ—¶é—´æ’åºï¼‰"""
        # è·å–æœ€è¿‘30å¤©å†…æ›´æ–°çš„é¡¹ç›®
        date_30_days_ago = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')

        # åˆ†å¤šæ¬¡æŸ¥è¯¢ä¸åŒçš„AIé¢†åŸŸ
        queries = [
            f'machine learning pushed:>{date_30_days_ago}',
            f'tensorflow OR pytorch pushed:>{date_30_days_ago}',
            f'nlp OR gpt pushed:>{date_30_days_ago}',
            f'"computer vision" pushed:>{date_30_days_ago}'
        ]

        all_projects = []
        for query in queries:
            projects = self.search_repositories(query, sort='updated', per_page=25)
            all_projects.extend(projects)
            time.sleep(1)  # é¿å…APIé™åˆ¶

        # å»é™¤é‡å¤é¡¹ç›®ï¼ˆåŸºäºIDï¼‰
        seen_ids = set()
        unique_projects = []
        for project in all_projects:
            if project['id'] not in seen_ids:
                seen_ids.add(project['id'])
                unique_projects.append(project)

        return unique_projects


class AIProjectFilter:
    """AIé¡¹ç›®è¯†åˆ«å’Œè¿‡æ»¤å™¨"""

    AI_KEYWORDS = [
        'artificial intelligence', 'machine learning', 'deep learning', 'neural network',
        'computer vision', 'nlp', 'natural language processing', 'chatbot', 'tensorflow',
        'pytorch', 'llm', 'gpt', 'transformer', 'reinforcement learning', 'data science',
        'ai', 'openai', 'llama', 'bert', 'stable diffusion', 'generative ai', 'langchain',
        'keras', 'scikit-learn', 'pandas', 'numpy', 'opencv', 'yolo', 'cnn', 'rnn',
        'lstm', 'gan', 'vae', 'autoencoder', 'embedding', 'classification', 'regression',
        'clustering', 'recommendation', 'speech recognition', 'text mining', 'sentiment analysis'
    ]

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def is_ai_project(self, repo: Dict) -> bool:
        """åˆ¤æ–­é¡¹ç›®æ˜¯å¦ä¸ºAIç›¸å…³é¡¹ç›®"""
        # å®‰å…¨åœ°å¤„ç†å¯èƒ½ä¸ºNoneçš„å­—æ®µ
        name = repo.get('name') or ''
        description = repo.get('description') or ''
        topics = repo.get('topics') or []

        text_fields = [
            name.lower(),
            description.lower(),
            ' '.join(topics).lower()
        ]

        full_text = ' '.join(text_fields)

        for keyword in self.AI_KEYWORDS:
            if keyword in full_text:
                return True

        return False

    def filter_ai_projects(self, projects: List[Dict]) -> List[Dict]:
        """è¿‡æ»¤å‡ºAIç›¸å…³é¡¹ç›®"""
        ai_projects = []
        for project in projects:
            if self.is_ai_project(project):
                ai_projects.append(project)

        self.logger.info(f"ä» {len(projects)} ä¸ªé¡¹ç›®ä¸­ç­›é€‰å‡º {len(ai_projects)} ä¸ªAIé¡¹ç›®")
        return ai_projects


class ProjectDeduplicator:
    """é¡¹ç›®å»é‡å™¨ï¼Œç®¡ç†å·²æ¨é€é¡¹ç›®è®°å½•"""

    def __init__(self, storage_file: str = 'sent_projects.json'):
        self.storage_file = storage_file
        self.logger = logging.getLogger(__name__)
        self.sent_projects = self._load_sent_projects()

    def _load_sent_projects(self) -> Dict:
        """åŠ è½½å·²æ¨é€é¡¹ç›®è®°å½•"""
        if os.path.exists(self.storage_file):
            try:
                with open(self.storage_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                self.logger.error(f"è¯»å–å·²æ¨é€é¡¹ç›®è®°å½•å¤±è´¥: {e}")
                return {}
        return {}

    def _save_sent_projects(self):
        """ä¿å­˜å·²æ¨é€é¡¹ç›®è®°å½•"""
        try:
            with open(self.storage_file, 'w', encoding='utf-8') as f:
                json.dump(self.sent_projects, f, ensure_ascii=False, indent=2)
        except IOError as e:
            self.logger.error(f"ä¿å­˜å·²æ¨é€é¡¹ç›®è®°å½•å¤±è´¥: {e}")

    def is_project_sent(self, repo_id: str) -> bool:
        """æ£€æŸ¥é¡¹ç›®æ˜¯å¦å·²æ¨é€"""
        return str(repo_id) in self.sent_projects

    def mark_project_as_sent(self, repo: Dict):
        """æ ‡è®°é¡¹ç›®ä¸ºå·²æ¨é€"""
        repo_id = str(repo['id'])
        self.sent_projects[repo_id] = {
            'name': repo['name'],
            'full_name': repo['full_name'],
            'sent_date': datetime.now().isoformat(),
            'stars': repo['stargazers_count'],
            'url': repo['html_url']
        }
        self._save_sent_projects()

    def clean_old_records(self, days: int = 30):
        """æ¸…ç†æ—§è®°å½•"""
        cutoff_date = datetime.now() - timedelta(days=days)
        to_remove = []

        for repo_id, project_info in self.sent_projects.items():
            try:
                sent_date = date_parser.parse(project_info['sent_date'])
                if sent_date < cutoff_date:
                    to_remove.append(repo_id)
            except (ValueError, TypeError):
                to_remove.append(repo_id)

        for repo_id in to_remove:
            del self.sent_projects[repo_id]

        if to_remove:
            self._save_sent_projects()
            self.logger.info(f"æ¸…ç†äº† {len(to_remove)} æ¡æ—§è®°å½•")

    def filter_new_projects(self, projects: List[Dict]) -> List[Dict]:
        """è¿‡æ»¤å‡ºæœªæ¨é€çš„é¡¹ç›®"""
        new_projects = []
        for project in projects:
            if not self.is_project_sent(project['id']):
                new_projects.append(project)

        self.logger.info(f"ä» {len(projects)} ä¸ªé¡¹ç›®ä¸­è¿‡æ»¤å‡º {len(new_projects)} ä¸ªæœªæ¨é€é¡¹ç›®")
        return new_projects

    def reset_sent_projects(self):
        """é‡ç½®å·²æ¨é€é¡¹ç›®è®°å½•ï¼Œæ¸…ç©ºæ‰€æœ‰è®°å½•"""
        self.sent_projects = {}
        self._save_sent_projects()
        self.logger.info("å·²é‡ç½®æ‰€æœ‰æ¨é€è®°å½•ï¼Œä¸‹æ¬¡å°†æ¨é€æœ€çƒ­é—¨çš„é¡¹ç›®")

    def get_stats(self) -> Dict:
        """è·å–æ¨é€ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_sent': len(self.sent_projects),
            'latest_sent': max([proj['sent_date'] for proj in self.sent_projects.values()]) if self.sent_projects else None,
            'storage_file': self.storage_file
        }


class ProjectSummarizer:
    """é¡¹ç›®æ€»ç»“ç”Ÿæˆå™¨ï¼Œç”Ÿæˆæœ‰è¯´æœåŠ›çš„é¡¹ç›®ä»‹ç»"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def generate_summary(self, repo: Dict) -> str:
        """ç”Ÿæˆé¡¹ç›®çš„æ™ºèƒ½æ€»ç»“"""
        try:
            name = repo.get('name', '')
            description = repo.get('description', '')
            stars = repo.get('stargazers_count', 0)
            forks = repo.get('forks_count', 0)
            language = repo.get('language', 'Unknown')
            topics = repo.get('topics', [])
            created_at = repo.get('created_at', '')
            updated_at = repo.get('updated_at', '')

            # è®¡ç®—é¡¹ç›®å¹´é¾„
            try:
                created_date = date_parser.parse(created_at)
                days_since_creation = max((datetime.now().replace(tzinfo=None) -
                                         created_date.replace(tzinfo=None)).days, 1)
                years = days_since_creation / 365.25
            except:
                years = 0

            # ç”Ÿæˆæ€»ç»“çš„ä¸åŒéƒ¨åˆ†
            popularity_reason = self._generate_popularity_reason(stars, forks, years)
            technical_highlights = self._generate_technical_highlights(name, description, language, topics)
            community_impact = self._generate_community_impact(stars, forks, years)

            # ç»„åˆæˆå®Œæ•´æ€»ç»“ï¼ˆä¼˜å…ˆæŠ€æœ¯äº®ç‚¹+å—æ¬¢è¿åŸå› ï¼‰
            summary_parts = []

            if technical_highlights:
                summary_parts.append(technical_highlights)

            if popularity_reason and len(popularity_reason) < 80:
                summary_parts.append(popularity_reason)

            # å¦‚æœæ€»ç»“å¤ªé•¿ï¼Œåªä½¿ç”¨æŠ€æœ¯äº®ç‚¹
            combined = " ".join(summary_parts)
            if len(combined) > 150:
                return technical_highlights if technical_highlights else description[:100]
            elif combined:
                return combined
            else:
                return description[:100] + "..." if len(description) > 100 else description

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆé¡¹ç›®æ€»ç»“å¤±è´¥: {e}")
            return repo.get('description', 'æš‚æ— æè¿°')[:100]

    def _generate_popularity_reason(self, stars: int, forks: int, years: float) -> str:
        """ç”Ÿæˆå—æ¬¢è¿åŸå› """
        if stars >= 100000:
            return f"ä½œä¸ºGitHubä¸Šæœ€å—æ¬¢è¿çš„é¡¹ç›®ä¹‹ä¸€ï¼Œ{stars:,}ä¸ªstarè¯æ˜äº†å…¶åœ¨å¼€å‘è€…ç¤¾åŒºä¸­çš„ç»Ÿæ²»åœ°ä½ã€‚"
        elif stars >= 50000:
            return f"å‡­å€Ÿ{stars:,}ä¸ªstarå’Œ{forks:,}ä¸ªforkï¼Œå·²æˆä¸ºè¯¥é¢†åŸŸçš„æ ‡æ†é¡¹ç›®ã€‚"
        elif stars >= 20000:
            return f"è·å¾—{stars:,}ä¸ªstarï¼Œåœ¨å¼€å‘è€…ä¸­äº«æœ‰å¾ˆé«˜å£°èª‰ã€‚"
        elif stars >= 5000:
            if years < 1:
                return f"è™½ç„¶åˆ›å»ºä¸åˆ°ä¸€å¹´ï¼Œä½†å·²è·å¾—{stars:,}ä¸ªstarï¼Œå±•ç°å‡ºå¼ºåŠ²çš„å¢é•¿åŠ¿å¤´ã€‚"
            else:
                return f"æŒç»­è·å¾—ç¤¾åŒºè®¤å¯ï¼Œ{stars:,}ä¸ªstarä½“ç°äº†å…¶å®ç”¨ä»·å€¼ã€‚"
        elif stars >= 1000:
            if years < 0.5:
                return f"ä½œä¸ºæ–°å…´é¡¹ç›®ï¼Œ{stars:,}ä¸ªstaræ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚"
            else:
                return f"{stars:,}ä¸ªstarè¡¨æ˜å…¶åœ¨ç‰¹å®šé¢†åŸŸçš„å½±å“åŠ›ã€‚"
        else:
            return f"æ­£åœ¨å¿«é€Ÿå‘å±•ä¸­çš„é¡¹ç›®ï¼Œå·²è·å¾—{stars}ä¸ªstarã€‚"

    def _generate_technical_highlights(self, name: str, description: str, language: str, topics: List[str]) -> str:
        """ç”ŸæˆæŠ€æœ¯äº®ç‚¹"""
        name_lower = name.lower()
        desc_lower = description.lower()
        topics_str = ' '.join(topics).lower()
        text = f"{name_lower} {desc_lower} {topics_str}"

        # AI/MLæ¡†æ¶å’Œåº“
        if any(keyword in text for keyword in ['tensorflow', 'pytorch', 'keras', 'scikit-learn']):
            if 'tensorflow' in text:
                return "TensorFlowç”Ÿæ€ç³»ç»Ÿä¸­çš„é‡è¦ç»„ä»¶ï¼Œä¸ºæœºå™¨å­¦ä¹ æä¾›å¼ºå¤§æ”¯æŒã€‚"
            elif 'pytorch' in text:
                return "åŸºäºPyTorchæ„å»ºçš„æ·±åº¦å­¦ä¹ å·¥å…·ï¼Œæ·±å—ç ”ç©¶è€…å–œçˆ±ã€‚"
            elif 'keras' in text:
                return "Kerasé«˜çº§APIçš„ä¼˜ç§€å®ç°ï¼Œç®€åŒ–äº†æ·±åº¦å­¦ä¹ å¼€å‘æµç¨‹ã€‚"
            else:
                return "æœºå™¨å­¦ä¹ é¢†åŸŸçš„ä¸“ä¸šå·¥å…·ï¼Œæä¾›å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚"

        # å¤§è¯­è¨€æ¨¡å‹å’ŒNLP
        elif any(keyword in text for keyword in ['llm', 'gpt', 'transformer', 'bert', 'nlp', 'language model']):
            return "å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£çš„å…³é”®é¡¹ç›®ï¼Œæ¨åŠ¨äº†è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯çš„å‘å±•ã€‚"

        # è®¡ç®—æœºè§†è§‰
        elif any(keyword in text for keyword in ['computer vision', 'opencv', 'yolo', 'detection', 'recognition']):
            return "è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å…ˆè¿›å·¥å…·ï¼Œä¸ºå›¾åƒå¤„ç†å’Œè¯†åˆ«æä¾›çªç ´æ€§èƒ½åŠ›ã€‚"

        # æ•°æ®ç§‘å­¦å’Œåˆ†æ
        elif any(keyword in text for keyword in ['data science', 'pandas', 'numpy', 'jupyter', 'analysis']):
            return "æ•°æ®ç§‘å­¦å·¥ä½œæµçš„æ ¸å¿ƒå·¥å…·ï¼Œæå¤§æå‡äº†æ•°æ®åˆ†ææ•ˆç‡ã€‚"

        # AIå¼€å‘å·¥å…·
        elif any(keyword in text for keyword in ['ai tool', 'artificial intelligence', 'automation', 'assistant']):
            return "AIé©±åŠ¨çš„æ™ºèƒ½å·¥å…·ï¼Œä¸ºå¼€å‘è€…æä¾›å‰æ‰€æœªæœ‰çš„ç”Ÿäº§åŠ›æå‡ã€‚"

        # å¼€æºå­¦ä¹ èµ„æº
        elif any(keyword in text for keyword in ['tutorial', 'learning', 'course', 'education', 'beginner']):
            return "é«˜è´¨é‡çš„AIå­¦ä¹ èµ„æºï¼Œå¸®åŠ©æ— æ•°å¼€å‘è€…æŒæ¡äººå·¥æ™ºèƒ½æŠ€æœ¯ã€‚"

        # Webæ¡†æ¶å’Œåº”ç”¨
        elif any(keyword in text for keyword in ['web', 'api', 'server', 'framework', 'application']):
            if language in ['JavaScript', 'TypeScript', 'Python']:
                return f"åŸºäº{language}çš„ç°ä»£Webè§£å†³æ–¹æ¡ˆï¼Œé›†æˆäº†æœ€æ–°çš„AIèƒ½åŠ›ã€‚"
            else:
                return "èåˆAIæŠ€æœ¯çš„Webåº”ç”¨æ¡†æ¶ï¼Œå¼•é¢†æ–°ä¸€ä»£å¼€å‘æ¨¡å¼ã€‚"

        # é€šç”¨AIå·¥å…·
        elif any(keyword in text for keyword in ['ai', 'machine learning', 'deep learning', 'neural']):
            return "äººå·¥æ™ºèƒ½é¢†åŸŸçš„åˆ›æ–°é¡¹ç›®ï¼Œä¸ºAIå¼€å‘æä¾›å¼ºå¤§çš„æŠ€æœ¯æ”¯æ’‘ã€‚"

        else:
            # æ ¹æ®è¯­è¨€ç”Ÿæˆé€šç”¨æè¿°
            if language == 'Python':
                return "Pythonç”Ÿæ€ä¸­çš„ä¼˜ç§€é¡¹ç›®ï¼Œä»¥å…¶ç®€æ´å’Œå¼ºå¤§è‘—ç§°ã€‚"
            elif language == 'JavaScript':
                return "JavaScriptç¤¾åŒºçš„åˆ›æ–°æˆæœï¼Œæ¨åŠ¨äº†ç°ä»£Webå¼€å‘ã€‚"
            elif language == 'TypeScript':
                return "TypeScriptæ„å»ºçš„ç±»å‹å®‰å…¨è§£å†³æ–¹æ¡ˆï¼Œæå‡å¼€å‘ä½“éªŒã€‚"
            elif language == 'Rust':
                return "Rustè¯­è¨€çš„é«˜æ€§èƒ½å®ç°ï¼Œå…¼é¡¾å®‰å…¨æ€§å’Œæ•ˆç‡ã€‚"
            elif language == 'Go':
                return "Goè¯­è¨€çš„ç®€æ´å®ç°ï¼Œä¸“æ³¨äºé«˜å¹¶å‘å’Œå¯ç»´æŠ¤æ€§ã€‚"
            else:
                return f"åŸºäº{language}å¼€å‘çš„ä¸“ä¸šå·¥å…·ï¼Œè§£å†³äº†å®é™…ä¸šåŠ¡éœ€æ±‚ã€‚"

    def _generate_community_impact(self, stars: int, forks: int, years: float) -> str:
        """ç”Ÿæˆç¤¾åŒºå½±å“æè¿°"""
        fork_ratio = forks / max(stars, 1)

        if fork_ratio > 0.3:
            return "æ´»è·ƒçš„è´¡çŒ®è€…ç¤¾åŒºå’Œä¸°å¯Œçš„forkæ•°é‡æ˜¾ç¤ºäº†é¡¹ç›®çš„å¥åº·å‘å±•æ€åŠ¿ã€‚"
        elif fork_ratio > 0.15:
            return "è‰¯å¥½çš„ç¤¾åŒºå‚ä¸åº¦è¡¨æ˜é¡¹ç›®å…·æœ‰æŒç»­çš„å‘å±•åŠ¨åŠ›ã€‚"
        elif stars > 1000:
            return "è™½ç„¶forkè¾ƒå°‘ï¼Œä½†é«˜staræ•°æ˜¾ç¤ºäº†é¡¹ç›®çš„é«˜è´¨é‡å’Œå®ç”¨æ€§ã€‚"
        else:
            return "æ­£åœ¨å»ºç«‹ç¤¾åŒºåŸºç¡€ï¼Œå±•ç°å‡ºè‰¯å¥½çš„å‘å±•å‰æ™¯ã€‚"


class TrendAnalyzer:
    """è¶‹åŠ¿åˆ†æå™¨ï¼Œè®¡ç®—é¡¹ç›®è¶‹åŠ¿åˆ†æ•°"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def calculate_trend_score(self, repo: Dict) -> float:
        """è®¡ç®—é¡¹ç›®è¶‹åŠ¿åˆ†æ•°"""
        try:
            created_at = date_parser.parse(repo['created_at'])
            # ç¡®ä¿ä¸¤ä¸ªdatetimeéƒ½æ˜¯naiveç±»å‹
            if created_at.tzinfo is not None:
                created_at = created_at.replace(tzinfo=None)

            days_since_creation = max((datetime.now() - created_at).days, 1)

            stars = repo.get('stargazers_count', 0)
            forks = repo.get('forks_count', 0)

            # è¶‹åŠ¿åˆ†æ•° = (stars/é¡¹ç›®å¤©æ•°) * 0.7 + (forks/é¡¹ç›®å¤©æ•°) * 0.3
            daily_stars = stars / days_since_creation
            daily_forks = forks / days_since_creation

            trend_score = daily_stars * 0.7 + daily_forks * 0.3

            return trend_score
        except Exception as e:
            self.logger.error(f"è®¡ç®—è¶‹åŠ¿åˆ†æ•°å¤±è´¥: {e}")
            return 0.0

    def sort_by_trend_score(self, projects: List[Dict]) -> List[Dict]:
        """æŒ‰è¶‹åŠ¿åˆ†æ•°æ’åºé¡¹ç›®"""
        for project in projects:
            project['trend_score'] = self.calculate_trend_score(project)

        sorted_projects = sorted(projects, key=lambda x: x['trend_score'], reverse=True)
        self.logger.info(f"æŒ‰è¶‹åŠ¿åˆ†æ•°æ’åºäº† {len(sorted_projects)} ä¸ªé¡¹ç›®")
        return sorted_projects


class DiscordNotifier:
    """Discordæ¶ˆæ¯æ¨é€å™¨"""

    def __init__(self, webhook_url: Optional[str] = None, summarizer: Optional['ProjectSummarizer'] = None):
        self.webhook_url = webhook_url or os.getenv('DISCORD_WEBHOOK_URL')
        self.summarizer = summarizer or ProjectSummarizer()
        self.logger = logging.getLogger(__name__)

    def format_project_info(self, repo: Dict, rank: int) -> str:
        """æ ¼å¼åŒ–é¡¹ç›®ä¿¡æ¯ï¼ˆåŒ…å«æ™ºèƒ½æ€»ç»“ï¼‰"""
        name = repo['name']
        stars = repo['stargazers_count']
        forks = repo['forks_count']
        url = repo['html_url']
        language = repo.get('language', 'Unknown')

        # ç”Ÿæˆæ™ºèƒ½æ€»ç»“
        summary = self.summarizer.generate_summary(repo)

        # é™åˆ¶æ€»ç»“é•¿åº¦ï¼Œç¡®ä¿Discordæ¶ˆæ¯ä¸ä¼šå¤ªé•¿
        if len(summary) > 120:
            summary = summary[:120] + '...'

        return f"{rank}. **{name}** - â­{stars:,} ğŸ´{forks:,} ğŸ“{language}\n   ğŸ’¡ {summary}\n   [ğŸ”— æŸ¥çœ‹é¡¹ç›®]({url})"

    def create_discord_embed(self, popular_projects: List[Dict], trending_projects: List[Dict]) -> Dict:
        """åˆ›å»ºDiscord Embedæ¶ˆæ¯"""
        embed = {
            "title": "ğŸ¤– AIé¡¹ç›®æ—¥æŠ¥",
            "description": f"{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')} æœ€å€¼å¾—å…³æ³¨çš„AIå¼€æºé¡¹ç›®",
            "color": 5814783,  # è“è‰²
            "fields": [],
            "timestamp": datetime.now().isoformat()
        }

        # æ·»åŠ çƒ­é—¨é¡¹ç›®
        if popular_projects:
            popular_text = "\n\n".join([
                self.format_project_info(repo, i+1)
                for i, repo in enumerate(popular_projects[:5])
            ])
            embed["fields"].append({
                "name": "â­ æ”¶è—æœ€å¤šçš„AIé¡¹ç›®",
                "value": popular_text,
                "inline": False
            })

        # æ·»åŠ è¶‹åŠ¿é¡¹ç›®
        if trending_projects:
            trending_text = "\n\n".join([
                self.format_project_info(repo, i+1)
                for i, repo in enumerate(trending_projects[:5])
            ])
            embed["fields"].append({
                "name": "ğŸ“ˆ è¶‹åŠ¿ä¸Šå‡æœ€å¿«çš„AIé¡¹ç›®",
                "value": trending_text,
                "inline": False
            })

        return {"embeds": [embed]}

    def send_notification(self, popular_projects: List[Dict], trending_projects: List[Dict]) -> bool:
        """å‘é€Discordé€šçŸ¥"""
        if not self.webhook_url:
            self.logger.error("Discord Webhook URLæœªé…ç½®")
            return False

        payload = self.create_discord_embed(popular_projects, trending_projects)

        try:
            response = requests.post(self.webhook_url, json=payload)
            response.raise_for_status()
            self.logger.info("Discordæ¶ˆæ¯å‘é€æˆåŠŸ")
            return True
        except requests.exceptions.RequestException as e:
            self.logger.error(f"Discordæ¶ˆæ¯å‘é€å¤±è´¥: {e}")
            return False


class AIGitHubTracker:
    """AI GitHubè¿½è¸ªå™¨ä¸»æ§åˆ¶å™¨"""

    def __init__(self):
        self.setup_logging()
        self.github_client = GitHubAPIClient()
        self.ai_filter = AIProjectFilter()
        self.deduplicator = ProjectDeduplicator()
        self.trend_analyzer = TrendAnalyzer()
        self.summarizer = ProjectSummarizer()
        self.notifier = DiscordNotifier(summarizer=self.summarizer)
        self.logger = logging.getLogger(__name__)

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('ai_tracker.log', encoding='utf-8')
            ]
        )

    def run_daily_tracking(self):
        """æ‰§è¡Œæ¯æ—¥è¿½è¸ªä»»åŠ¡"""
        self.logger.info("å¼€å§‹æ‰§è¡ŒAI GitHubé¡¹ç›®æ¯æ—¥è¿½è¸ªä»»åŠ¡")

        try:
            # 1. æ¸…ç†æ—§è®°å½•
            self.deduplicator.clean_old_records()

            # 2. è·å–é¡¹ç›®æ•°æ®
            self.logger.info("æ­£åœ¨è·å–GitHubé¡¹ç›®æ•°æ®...")
            popular_repos = self.github_client.get_popular_ai_projects()
            trending_repos = self.github_client.get_trending_ai_projects()

            if not popular_repos and not trending_repos:
                self.logger.error("æœªèƒ½è·å–åˆ°ä»»ä½•é¡¹ç›®æ•°æ®")
                return

            # 3. AIé¡¹ç›®è¿‡æ»¤
            popular_ai_projects = self.ai_filter.filter_ai_projects(popular_repos)
            trending_ai_projects = self.ai_filter.filter_ai_projects(trending_repos)

            # 4. å»é‡è¿‡æ»¤
            new_popular_projects = self.deduplicator.filter_new_projects(popular_ai_projects)
            new_trending_projects = self.deduplicator.filter_new_projects(trending_ai_projects)

            # 5. è¶‹åŠ¿åˆ†æ
            trending_sorted = self.trend_analyzer.sort_by_trend_score(new_trending_projects)

            # 6. é€‰æ‹©è¦æ¨é€çš„é¡¹ç›®
            selected_popular = new_popular_projects[:5]  # å‰5ä¸ªçƒ­é—¨é¡¹ç›®
            selected_trending = trending_sorted[:5]      # å‰5ä¸ªè¶‹åŠ¿é¡¹ç›®

            if not selected_popular and not selected_trending:
                self.logger.info("æ²¡æœ‰å‘ç°æ–°çš„AIé¡¹ç›®ï¼Œä»Šæ—¥ä¸æ¨é€")
                return

            # 7. å‘é€é€šçŸ¥
            if self.notifier.send_notification(selected_popular, selected_trending):
                # 8. æ ‡è®°é¡¹ç›®ä¸ºå·²æ¨é€
                for project in selected_popular + selected_trending:
                    self.deduplicator.mark_project_as_sent(project)

                self.logger.info(f"æˆåŠŸæ¨é€ {len(selected_popular)} ä¸ªçƒ­é—¨é¡¹ç›®å’Œ {len(selected_trending)} ä¸ªè¶‹åŠ¿é¡¹ç›®")
            else:
                self.logger.error("æ¶ˆæ¯æ¨é€å¤±è´¥")

        except Exception as e:
            self.logger.error(f"æ‰§è¡Œè¿½è¸ªä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='AI GitHub Daily Tracker - AIé¡¹ç›®æ¯æ—¥è¿½è¸ªå™¨')
    parser.add_argument('--reset', action='store_true',
                       help='é‡ç½®å·²æ¨é€é¡¹ç›®è®°å½•ï¼Œä¸‹æ¬¡å°†æ¨é€æœ€çƒ­é—¨çš„é¡¹ç›®')
    parser.add_argument('--stats', action='store_true',
                       help='æ˜¾ç¤ºæ¨é€ç»Ÿè®¡ä¿¡æ¯')

    args = parser.parse_args()

    tracker = AIGitHubTracker()

    if args.reset:
        print("ğŸ”„ é‡ç½®å·²æ¨é€é¡¹ç›®è®°å½•...")
        tracker.deduplicator.reset_sent_projects()
        print("âœ… é‡ç½®å®Œæˆï¼ä¸‹æ¬¡è¿è¡Œå°†æ¨é€æœ€çƒ­é—¨çš„AIé¡¹ç›®ã€‚")
        return

    if args.stats:
        stats = tracker.deduplicator.get_stats()
        print("ğŸ“Š æ¨é€ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  å·²æ¨é€é¡¹ç›®æ€»æ•°: {stats['total_sent']}")
        print(f"  æœ€åæ¨é€æ—¶é—´: {stats['latest_sent'] or 'N/A'}")
        print(f"  å­˜å‚¨æ–‡ä»¶: {stats['storage_file']}")
        return

    # é»˜è®¤è¿è¡Œæ—¥å¸¸è¿½è¸ª
    tracker.run_daily_tracking()


if __name__ == "__main__":
    main()